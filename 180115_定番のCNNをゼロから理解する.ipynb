{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "参考（ここに書かれていることをやった）\n",
    "https://deepage.net/deep_learning/2016/11/07/convolutional_neural_network.html\n",
    "http://tecmemo.wpblog.jp/category/machine-learning/deep-learning/tensorflow/\n",
    "\n",
    "（wやxの定義の仕方の理解に役立つ）\n",
    "https://endoyuta.com/2017/01/18/tensorflow-%E7%95%B3%E3%81%BF%E8%BE%BC%E3%81%BF%E6%BC%94%E7%AE%97%E3%81%AE%E9%96%A2%E6%95%B0-tf-nn-conv2d/\n",
    "（震探データに応用する際に重要な，channelの扱いについて書かれている)\n",
    "https://qiita.com/YusukeSuzuki@github/items/0764d15b9d0b97ec1e16\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_dataset/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_dataset/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_dataset/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_dataset/t10k-labels-idx1-ubyte.gz\n",
      "step=0/accuracy=0.1876000016927719\n",
      "step=100/accuracy=0.20190000534057617\n",
      "step=200/accuracy=0.10520000010728836\n",
      "step=300/accuracy=0.10520000010728836\n",
      "step=400/accuracy=0.10520000010728836\n",
      "step=500/accuracy=0.10520000010728836\n",
      "step=600/accuracy=0.10520000010728836\n",
      "step=700/accuracy=0.10520000010728836\n",
      "step=800/accuracy=0.10520000010728836\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-bdde28a9d80a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mt_batch\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[0mresult\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'step={}/accuracy={}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "######     設定部     #########\n",
    "#conv1\n",
    "filter_height_conv1=5#filter縦長さ\n",
    "filter_width_conv1=5#filter横長さ\n",
    "num_of_conv1_opchannels=32\n",
    "dx_conv1=1#横方向ストライド\n",
    "dy_conv1=1#縦方向ストライド\n",
    "#pool1\n",
    "k_height_pool1=2\n",
    "k_width_pool1=2\n",
    "dy_pool1=2\n",
    "dx_pool1=2\n",
    "#conv2\n",
    "filter_height_conv2=5#filter縦長さ\n",
    "filter_width_conv2=5#filter横長さ\n",
    "num_of_conv2_opchannels=64\n",
    "dx_conv2=1\n",
    "dy_conv2=1\n",
    "#pool1\n",
    "k_height_pool2=2\n",
    "k_width_pool2=2\n",
    "dy_pool2=2\n",
    "dx_pool2=2\n",
    "#fc1\n",
    "num_of_op_nodes_fc1=1024\n",
    "#fc2\n",
    "num_of_op_nodes_fc2=10\n",
    "\n",
    "learning_rate=0.00001\n",
    "num_of_steps=20000\n",
    "batch_size=50\n",
    "#############################\n",
    "#cnnは，普通のニューラルネットワークと基本的には同じ構造．\n",
    "#ただ，\"node（数字）\"の部分が\"channel（テンソル）\"になっている．\n",
    "#フィルタサイズ(a,b), input-channelの要素数i, output-channelの要素数jというのは，\n",
    "#wというvariablesは，i行j列の，一個一個の要素がサイズ(a,b)のテンソル（＝フィルタ）である，というイメージ．\n",
    "\n",
    "#MNISTデータのダウンロード\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_dataset/\", one_hot=True)\n",
    "\n",
    "\n",
    "def conv2d(x,w,b,dy,dx):\n",
    "    op_conv2d=tf.nn.conv2d(x, w, strides=[1,dy,dx,1],padding='SAME')+b\n",
    "    #nn.cnnv2dは，フィルター内のxとwの対応する要素同士を掛け，その和を返す．\n",
    "    #stridesは，[1, dy, dx, 1]となっていて，縦方向にdy，横方向にdxピクセル幅でフィルタを動かす\n",
    "    #paddding=sameは，フィルター内に一か所でももともとのデータがある場所なら，残りをゼロで埋める\n",
    "    op_conv2d=tf.nn.relu(op_conv2d)#reluは活性化関数．sigmoidみたいなもん．o以上の値に直す\n",
    "    return op_conv2d\n",
    "\n",
    "def max_pool(x,k_height,k_width,dy, dx):\n",
    "    op_pool=tf.nn.max_pool(x, ksize=[1, k_height, k_width, 1],\n",
    "                          strides=[1, dy, dx, 1], padding=\"SAME\")\n",
    "    return op_pool    \n",
    "\n",
    "X=tf.placeholder(\"float\", [None, 784])#input dataの[batch，縦，横，チャンネル数]\n",
    "X_image=tf.reshape(X, [-1, 28, 28,1])\n",
    "t=tf.placeholder(\"float\", [None, 10])\n",
    "\n",
    "#conv1\n",
    "w_conv1=tf.Variable(tf.random_normal([filter_height_conv1, filter_width_conv1, 1, num_of_conv1_opchannels]))\n",
    "#wはフィルターテンソル．[縦，横，入力チャネル数，出力チャネル数]\n",
    "#入力チャネル（=nodeな気がする）数は，白黒なら1，RGBなら3のように，ある場所がもつ要素の数\n",
    "#tf.nn.conv2dでは，input channnelが複数ある場合，output channelにはそれらの合計値が出される．\n",
    "#出力チャネル数は，num_of_hidden_nodes的なものなので，自由に決めてよい（2の乗数が一般的）\n",
    "b_conv1=tf.Variable(tf.random_normal([num_of_conv1_opchannels]))\n",
    "#filter w+b を，位置普遍性を保つように最適化していくというのがコンセプトなので，\n",
    "#w及びbは，input_channel*output_channel個づつになる．\n",
    "#ただし，wは5*5などの形を持っているため，このようになる．．\n",
    "op_conv1=conv2d(X_image, w_conv1,b_conv1,dy_conv1, dx_conv1)\n",
    "\n",
    "#pool1\n",
    "op_pool1=max_pool(op_conv1,k_height_pool1,k_width_pool1,dy_pool1,dx_pool1)\n",
    "\n",
    "#conv2\n",
    "w_conv2=tf.Variable(tf.random_normal([filter_height_conv2, filter_width_conv2,\n",
    "                                      num_of_conv1_opchannels, num_of_conv2_opchannels]))\n",
    "b_conv2=tf.Variable(tf.random_normal([num_of_conv2_opchannels]))\n",
    "op_conv2=conv2d(op_pool1, w_conv2,b_conv2,dy_conv2, dx_conv2)\n",
    "\n",
    "#pool2\n",
    "op_pool2=max_pool(op_conv2, k_height_pool2, k_width_pool2, dy_pool2, dx_pool2)\n",
    "\n",
    "#全結合層1\n",
    "op_pool2_height=round(28/dy_conv1/dy_conv2/dy_pool1/dy_pool2)\n",
    "op_pool2_width=round(28/dx_conv1/dx_conv2/dx_pool1/dx_pool2)\n",
    "op_pool2=tf.reshape(op_pool2,[-1, op_pool2_height*op_pool2_width*num_of_conv2_opchannels])\n",
    "w_fc1=tf.Variable(tf.random_normal([op_pool2_height*op_pool2_width*num_of_conv2_opchannels, num_of_op_nodes_fc1]))\n",
    "b_fc1=tf.Variable(tf.random_normal([num_of_op_nodes_fc1]))\n",
    "op_fc1=tf.nn.relu(tf.matmul(op_pool2, w_fc1)+b_fc1)\n",
    "\n",
    "#全結合層2\n",
    "w_fc2=tf.Variable(tf.random_normal([num_of_op_nodes_fc1, num_of_op_nodes_fc2]))\n",
    "b_fc2=tf.Variable(tf.random_normal([num_of_op_nodes_fc2]))\n",
    "op_fc2=tf.nn.softmax(tf.matmul(op_fc1, w_fc2)+b_fc2)\n",
    "\n",
    "cross_entropy=-tf.reduce_sum(t*tf.log(tf.clip_by_value(op_fc2, 1e-10, 1.0)))#tのplaceholderの定義を必要とするのは実際にはここ以降\n",
    "\n",
    "#optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cross_entropy)\n",
    "optimizer=tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "\n",
    "#for tensorboard\n",
    "#tf.summary.scalar(\"cross_entropy\", cross_entropy)\n",
    "#summary_op=tf.summary.merge_all()\n",
    "\n",
    "#評価用\n",
    "correct_prediction=tf.equal(tf.argmax(op_fc2,1), tf.argmax(t,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #summary_writer=tf.summary.FileWriter('.\\logs/180115', sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range (num_of_steps):\n",
    "        x_batch,t_batch=mnist.train.next_batch(batch_size)\n",
    "\n",
    "        sess.run(optimizer, feed_dict={X:x_batch, t:t_batch})\n",
    "        if step % 100 == 0:\n",
    "            result=sess.run(accuracy, feed_dict={X: mnist.test.images, t: mnist.test.labels})\n",
    "            print('step={}/accuracy={}'.format(step, result))\n",
    "            \n",
    "            #wc1=sess.run(w_conv1)\n",
    "            #print('w_conv1=\\n',wc1)\n",
    "            \n",
    "            #summary=sess.run(summary_op,feed_dict={X: mnist.test.images, t: mnist.test.labels})\n",
    "            #summary_writer.add_summary(summary,step)\n",
    "            \n",
    "    result=sess.run(accuracy, feed_dict={X: mnist.test.images, t: mnist.test.labels})\n",
    "    print(\"final_accuracy=\\n\",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_133:0' shape=(2, 2, 3, 4) dtype=float32_ref>\n",
      "[[[[ 0.37061283 -1.3806987   0.8084075   0.9719897 ]\n",
      "   [-0.2629388   1.7086697   1.2886996   0.6605297 ]\n",
      "   [-1.4800066   1.0990572   0.53192234 -0.8736463 ]]\n",
      "\n",
      "  [[ 1.7176734   0.13660447 -0.7850778  -1.5814241 ]\n",
      "   [-1.7370864   1.08038    -1.039911    1.7904675 ]\n",
      "   [-0.38866213 -0.07242326 -1.083528   -0.64173394]]]\n",
      "\n",
      "\n",
      " [[[-0.8982141   1.3345892  -0.62835425 -0.15981498]\n",
      "   [-0.0722959  -0.22174725 -0.6626167  -0.2308909 ]\n",
      "   [ 0.1832864   0.7508374   0.60154486  1.9067985 ]]\n",
      "\n",
      "  [[-1.3113804  -0.37368625  1.1420406   0.70210665]\n",
      "   [ 1.124935    0.59519947  0.9509193   0.44264832]\n",
      "   [ 1.477632    0.7944328   1.5487107  -0.18196186]]]]\n"
     ]
    }
   ],
   "source": [
    "#確認variableの定義の仕方\n",
    "import tensorflow as tf\n",
    "a=tf.Variable(tf.random_normal([2, 2, 3, 4]))\n",
    "print(a)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "#確認用2: 切り上げ\n",
    "print(round(12/4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    " \n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    " \n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    " \n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "   \n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    " \n",
    "# ニューラルネットワークを計算グラフで作成する\n",
    "# 第1層 (入力層)\n",
    "x = tf.placeholder(\"float\", [None, 784])\n",
    " \n",
    "# 形状変更\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    " \n",
    "# 第2層 (畳み込み層)\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "y_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    " \n",
    "# 第3層 (プーリング層)\n",
    "y_pool1 = max_pool_2x2(y_conv1)\n",
    " \n",
    "# 第4層 (畳み込み層)\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "y_conv2 = tf.nn.relu(conv2d(y_pool1, W_conv2) + b_conv2)\n",
    " \n",
    "# 第5層 (プーリング層)\n",
    "y_pool2 = max_pool_2x2(y_conv2)\n",
    " \n",
    "# 形状変更\n",
    "y_pool2_flat = tf.reshape(y_pool2, [-1, 7 * 7 * 64])\n",
    " \n",
    "# 第6層 (全結合層)\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "y_fc1 = tf.nn.relu(tf.matmul(y_pool2_flat, W_fc1) + b_fc1)\n",
    " \n",
    "# 第7層 (全結合層)\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "y = tf.nn.softmax(tf.matmul(y_fc1, W_fc2) + b_fc2)\n",
    " \n",
    "# 損失関数を計算グラフを作成する\n",
    "t = tf.placeholder(\"float\", [None, 10])\n",
    "cross_entropy = -tf.reduce_sum(t * tf.log(y))\n",
    " \n",
    "# 次の(1)、(2)を行うための計算グラフを作成する。\n",
    "# (1) 損失関数に対するネットワークを構成するすべての変数の勾配を計算する。\n",
    "# (2) 勾配方向に学習率分移動して、すべての変数を更新する。\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    " \n",
    "# 初期化を行うための計算グラフを作成する。\n",
    "init = tf.global_variables_initializer()\n",
    " \n",
    "# テストデータに対する正答率を計算するための計算グラフを作成する。\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(t, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    " \n",
    "# MNIST 入力データ\n",
    "mnist = input_data.read_data_sets(\"data/\", one_hot=True)\n",
    " \n",
    "# セッションを作成して、計算グラフを実行する。\n",
    "with tf.Session() as sess:\n",
    "   \n",
    "    # 初期化を実行する。\n",
    "    sess.run(init)\n",
    "   \n",
    "    # 学習を実行する。\n",
    "    for i in range(20000):\n",
    "        x_batch, t_batch = mnist.train.next_batch(50)\n",
    "        sess.run(train_step, feed_dict={x: x_batch, t: t_batch})\n",
    "         \n",
    "        if i % 100 == 0:\n",
    "            result = sess.run(accuracy, feed_dict={x: mnist.test.images, t: mnist.test.labels})\n",
    "            print(result)\n",
    " \n",
    "    result = sess.run(accuracy, feed_dict={x: mnist.test.images, t: mnist.test.labels})\n",
    "    print(\"accuracy:\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
